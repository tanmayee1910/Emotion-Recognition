# Emotion-Recognition
Face Emotion Recognition from Facial Expressions using Deep leaning Techniques
## Problem Definition
The stimulation of particular facial muscles allows humans to transmit their emotions through their faces. These expressions are sometimes accurate, but they can be difficult to grasp; signals in a face
expression can contain a wealth of information about their emotional state. Humans are generally adept at recognizing and comprehending the emotions of others. “Anger,“, “contempt, “,“disgust,
“, “fear, “,“happiness,”, “sadness, “, and “surprise,“ are among the seven emotions of human face that can be roughly classified. This project will use Python to implement the source code for a
facial expression recognition system. We’ll use the deep neural network to solve complicated issues like facial expression detection. 
In today’s world of computer vision, facial expression detection
systems are extremely important. It helps to comprehend the underlying meaning of human-machine interaction, which is useful in a variety of applications such as diagnosing mental diseases, assessing mental states, detecting lies,
and so on. The task of accurately recognising human expressions remains difficult. Deep learning techniques, which are particularly successful for image processing, are used here. The FER2013
dataset is used for analysis, and popular “Deep Learning (DL)“ frameworks for example OpenCV and Efficientnet are employed to accurately detect facial emotions.
## Dataset Description
FERR2013 is a collection of 48x48 facial photos with a variety of expressions. Faces in the Fer2013 dataset were automatically collected. As a result, the captured human face is centred then occupies
the similer amount of size in each frame. The results of each emotion’s Google image search, as well as alternatives for the feelings, were compiled into this dataset.
Fer2013 datasets are used in a variety of applications that involve making decisions about facial expression detection tasks. Traditional methods, deep learning, pre-trained models, and ensemble
neural networks techniques are used to handle these difficulties.
## Conclusion and Futurescope
We contributed to tackling the problem of improving facial expression recognition accuracy on FER2013 with our model, Efficientnet V2, which achieved the highest accuracy value. In the
future, more effort might be done to improve results by training using the Vision Transformer model and capable hardware resources. Ensemble models, which include VGGSpinalNet and other
models, can be employed in future research to increase accuracy even more.
